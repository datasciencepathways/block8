{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting Part 2: Template-based Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, the elixir icons that appear in the different locations of image are exact copies of the template. So, comparing them to the template using normalized cross-correlation will give us a result very close to 1.0 in all cases. Now, what if we want to use template matching to detect faces in an image? For simplicity we will only assume frontal views of faces. Different faces have more or less the same shape, but they also have differences, e.g. some people wear glasses, some people wear a hat, some people have a beard, etc. Using the face of a particular person as a template would probably work well for some people, but not for others. To create a template that is more likely to match most people, we can create an \"average face\" by taking the average multiple faces from a large dataset.\n",
    "\n",
    "Let's load a few faces from our face dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "# Load faces dataset\n",
    "filenames = [\n",
    "    'data/faces/04279d11.bmp', \n",
    "    'data/faces/04282d01.bmp',\n",
    "    'data/faces/04286d11.bmp',\n",
    "    'data/faces/04287d11.bmp',\n",
    "    'data/faces/04295d11.bmp',\n",
    "    'data/faces/04301d11.bmp'\n",
    "    ]\n",
    "\n",
    "# Load images\n",
    "images = [cv.imread(filename,cv.IMREAD_GRAYSCALE) for filename in filenames]\n",
    "\n",
    "# Display the images\n",
    "plt.figure(figsize = (10,5))\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(2,3,i+1), plt.imshow(images[i], cmap='gray')\n",
    "    plt.title(filenames[i]), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computer average face\n",
    "average_face = np.zeros((images[0].shape[0], images[0].shape[1]))\n",
    "for image in images:\n",
    "    average_face += image\n",
    "average_face /= len(images)\n",
    "\n",
    "# Display the average face\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(average_face, cmap='gray')\n",
    "plt.title('Average Face'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image above is the average of six faces from our dataset. Now let's compute the average face from all 337 faces in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images in the folder data/faces\n",
    "import os\n",
    "filenames = [ 'data/faces/' + filename for filename in os.listdir('data/faces') ]\n",
    "images = [cv.imread(filename,cv.IMREAD_GRAYSCALE) for filename in filenames]\n",
    "\n",
    "# Computer average face\n",
    "average_face = np.zeros((images[0].shape[0], images[0].shape[1]))\n",
    "for image in images:\n",
    "    average_face += image\n",
    "average_face /= len(images)\n",
    "\n",
    "# Display the average face\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(average_face, cmap='gray')\n",
    "plt.title('Average Face'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original size of the face images is 100x100 pixels. To increase the likelihood of a match, we will further crop the template and keep the parts of the average face that are most likely to be present in all faces:\n",
    "- Exclude background.\n",
    "- Exclude forehead (highly variable appearance, due to hair).\n",
    "- Exclude lower chin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the average face to a square of size 60x50\n",
    "average_face = average_face[25:85, 25:75]\n",
    "print(average_face.shape)\n",
    "\n",
    "plt.imshow(average_face, cmap='gray')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the average face template to detect faces in the image. Before we do so, we need to solve one more problem. Our template is of shape (61, 50) pixels. Therefore it can only work well for faces that are of the same size. It could also be that the faces are not in exactly the upright position. To solve this problem, we need to resize the template to different scales and will also rotate it to different orientations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliary function to rotate an image\n",
    "def rotate(image, angle, center = None):\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if center is None:\n",
    "        center = (w / 2, h / 2)\n",
    "\n",
    "    # Perform the rotation\n",
    "    M = cv.getRotationMatrix2D(center, angle, scale = 1.0)\n",
    "    rotated = cv.warpAffine(image, M, (w, h))\n",
    "\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of a multi-scale, multi-orientation template matching algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img = cv.imread('data/faces.jpg')\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "average_face = average_face.astype(np.uint8)\n",
    "\n",
    "\n",
    "# Loop over scales and rotations of the average face template\n",
    "for scale in np.arange(0.5, 1.5, 0.1):  # Scales\n",
    "    scaled_avg_face = cv.resize(average_face, None, fx = scale, fy = scale)\n",
    "\n",
    "    for angle in np.arange(-15, 15, 5):  # Rotate the average face from -15 to 15 degrees\n",
    "        scaled_and_rotated_avg_face = rotate(scaled_avg_face, angle)\n",
    "        h, w = scaled_and_rotated_avg_face.shape\n",
    "\n",
    "        result = cv.matchTemplate(img_gray, scaled_and_rotated_avg_face, cv.TM_CCOEFF_NORMED)\n",
    "        \n",
    "        # Specify a threshold\n",
    "        threshold = 0.6\n",
    "        # Find the location of the best match\n",
    "        loc = np.where( result >= threshold)\n",
    "\n",
    "        for pt in zip(*loc[::-1]):\n",
    "            # print(scale, pt)\n",
    "            cv.rectangle(img_gray, pt, (pt[0] + w, pt[1] + h), 255, 5)\n",
    "\n",
    "plt.figure(figsize = (10,15))\n",
    "plt.imshow(img_gray, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that with a threshold of 0.6 only two of the faces are detected. If we lower the threshold, we will likely detect more faces, but will also probably get false positives, i.e. areas of the image that are not faces will be detected as faces. \n",
    "\n",
    "Normalized cross-correlation is a good method to detect for detecting objects that are stable in their appearance. Although faces can be detected with this method, it is not the best face detection method. In future modules we will see how to use other methods to detect faces."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f63e3a62ec1190916fbae343a873902eb59c19028644989a00d46d3a746fcb45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
